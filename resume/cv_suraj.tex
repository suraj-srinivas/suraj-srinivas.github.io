
\documentclass[11pt,a4paper,sans,english]{moderncv}        % possible options include font size ('10pt', '11pt' and '12pt'), paper size ('a4paper', 'letterpaper', 'a5paper', 'legalpaper', 'executivepaper' and 'landscape') and font family ('sans' and 'roman')
\moderncvstyle{classic}                             % style options are 'casual' (default), 'classic', 'oldstyle' and 'banking'

\definecolor{mintcream}{RGB}{245,255,250}

\moderncvcolor{orange}                               % color options 'blue' (default), 'orange', 'green', 'red', 'purple', 'grey' and 'black'
\nopagenumbers{}                                  % uncomment to suppress automatic page numbering for CVs longer than one page
%\usepackage[utf8]{inputenc}                       % if you are not using xelatex ou lualatex, replace by the encoding you are using
\usepackage[a4paper, margin=2cm]{geometry}
\usepackage{setspace}
\usepackage{amssymb}
\RequirePackage[unicode]{hyperref}

\usepackage{cmbright}
\usepackage[OT1]{fontenc}

%\usepackage[scaled]{helvet}
%\usepackage[T1]{fontenc}

\definecolor{floralwhite}{RGB}{255,250,240}

\hypersetup{colorlinks = true,
            linkcolor = blue,
            urlcolor  = teal,
            citecolor = blue,
            anchorcolor = blue}
%\usepackage{babel}
%\usepackage{hyperref}
\setstretch{1.05}
\newcommand{\cvsection}[1]{\vspace{0.3cm}\subsection{\large{#1}}}
%\newcommand{\cvitem}[2]{def}
%----------------------------------------------------------------------------------
%            personal data
%----------------------------------------------------------------------------------
\firstname{\hspace{1em}\textcolor{darkgray}{\Huge{Suraj Srinivas}}}
\familyname{}
% \\ \vspace*{0.1cm} \normalsize{\faGlobe ~\href{https://suraj-srinivas.github.io}{suraj-srinivas.github.io}  $\cdot$  \faEnvelope~ ssrinivas@seas.harvard.edu $\cdot$  suuraj.srinivas@gmail.com} }
                                 
                                  
\begin{document}
\pagecolor{floralwhite}
%-----       resume       ---------------------------------------------------------
%\vspace*{-1cm}

\makecvtitle

\vspace{-1.5cm}
\textcolor{gray}{\hrule}

\cvsection{contact information}
%\cvitem{\faMapMarker~~~~}{6.220, 150 Western Ave \newline Harvard University, Boston, MA}
%\cvitem{\faEnvelope~~~}{suuraj.srinivas@gmail.com \newline ssrinivas@seas.harvard.edu}
%\cvitem{\faGlobe~~~}{\href{https://suraj-srinivas.github.io}{suraj-srinivas.github.io}}

\cvitem{}{6.220, 150 Western Ave \newline Harvard University, Boston, MA \vspace{1ex}\newline suuraj.srinivas@gmail.com \newline ssrinivas@seas.harvard.edu \newline \href{https://suraj-srinivas.github.io}{suraj-srinivas.github.io}}

\cvsection{research interests}
\cvitem{}{Robustness, Interpretability \& Computational Efficiency of Deep models;  \newline Generative modelling; Representation learning}

%\vspace{0.5cm}

\cvsection{work experience}
\cventry{01/2022 \newline - Present}{Postdoctoral Research Fellow}{}{\newline Harvard University, USA}
{\newline \textbf{Advisor}: Prof. Hima Lakkaraju
\newline \textbf{Duties}: 
Academic research $\cdot$ Technical guidance \& mentoring $\cdot$ Teaching}{}

\cvsection{education}
\cventry{2017 \newline - 2021}{Doctor of Philosophy}{}
{ \newline \'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne \& \newline Idiap Research Institute, Switzerland}
{ \newline \textbf{Advisor}: Prof. Fran\c{c}ois Fleuret}
{}
\vspace*{0.5em}

\cventry{2014\newline - 2017}{Master of Science (Engineering)}{}{\newline Indian Institute of Science, Bangalore, India}{ \newline \textbf{Advisor}: Prof. R. Venkatesh Babu}{} 
\vspace*{0.5em}
\cventry{2010\newline - 2014}{Bachelor of Engineering}{}{\newline PES University, Bangalore, India}{}{} 

\cvsection{internships}

\cventry{08/2020 \newline - 01/2021}{Research Intern}{Qualcomm AI Research, Netherlands}{\newline Research on algorithms
to sparsify neural networks}{}{}

\cventry{06/2016 \newline - 08/2016}{Research Intern}{DataGrokr, India / Verisk
Analytics, USA}{\newline Speeding up inference on deep neural networks using tensor factorization}{}{}

\cventry{01/2014 \newline - 06/2014}{Engineering Intern}{Tonbo Imaging, Bangalore}{}{\newline Implemented image
processing algorithms on FPGA for a thermal imaging camera}{}

\cventry{06/2013 \newline - 08/2013}{Research Intern}{Indian Institute of Science, Bangalore}{}{\newline
Research on computational photography to perform camera jitter compensation}{}

\clearpage
\cvsection{selected publications}
%\subsection{\small{\href{https://bit.ly/2keccl6}{google scholar profile}}}

\vspace{0.25cm}

\cvitem{2022} {\textbf{Suraj Srinivas}*, Kyle Matoba*, Hima Lakkaraju, Fran\c{c}ois Fleuret. (*co-first-author) \newline ``Efficient Training of Low-Curvature Neural Networks'' \newline{\textit{Neural Information Processing Systems (NeurIPS)}}
\newline Code: \href{https://github.com/kylematoba/lcnn}{github.com/kylematoba/lcnn} (Jointly authored)
}
\vspace*{0.25em}

\cvitem{2022} {Tessa Han, \textbf{Suraj Srinivas$^\dagger$}, Hima Lakkaraju. ($^\dagger$advising role)
\newline ``Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations''
\newline \textit{Neural Information Processing Systems (NeurIPS)} \newline \textit{ICML Interpretable ML for Healthcare Workshop} - \textbf{Best Paper Award}}
\vspace*{0.25em}

\cvitem{2022} {Marwa El Halabi, \textbf{Suraj Srinivas}, Simon Lacoste-Julien.
\newline ``Data-Efficient Structured Pruning via Submodular Optimization" \newline \textit{Neural Information Processing Systems (NeurIPS)}}

\vspace*{0.25em}
\cvitem{2022} {\textbf{Suraj Srinivas}, Andrey Kuzmin, Markus Nagel, Mart van Baalen, \newline Andrii Skliar, Tijmen Blankevoort. \newline ``Cyclical Pruning for Sparse Neural Networks" 
\newline \textit{Computer Vision and Pattern Recognition Workshops (CVPRW)} - \textbf{Oral}}

\vspace*{0.25em}
\cvitem{2021}{\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret. \newline ``Rethinking the Role of Gradient-based Attribution Methods in Model Interpretability" 
\newline \textit{International Conference on Learning Represetations (ICLR)} - \textbf{Oral}
\newline Code: \href{https://github.com/idiap/rethinking-saliency}{github.com/idiap/rethinking-saliency} 
}
\vspace*{0.25em}

\cvitem{2019} {\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret. \newline ``Full-Gradient Representation
for Neural Network Visualization" \newline \textit{Neural Information Processing Systems (NeurIPS)}
\newline Code: \href{https://github.com/idiap/fullgrad-saliency}{github.com/idiap/fullgrad-saliency}
}
\vspace*{0.25em}

\cvitem{2018} {\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret.
\newline ``Knowledge Transfer with Jacobian Matching" 
\newline \textit{International Conference on Machine Learning (ICML)}
\newline \textit{NeurIPS Learning with Limited Data (LLD) Workshop} - \textbf{Best Paper Award}
}
\vspace*{0.25em}

\cvitem{2017}{\textbf{Suraj Srinivas}, Akshayvarun Subramanya, R. Venkatesh Babu. 
\newline ``Training
Sparse Neural Networks"
\newline \textit{Computer Vision and Pattern Recognition Workshops (CVPRW)} - \textbf{Oral} }

\vspace*{0.25em}

\cvitem{2016}{\textbf{Suraj Srinivas}, R. Venkatesh Babu. 
\newline ``Learning the Architecture of Deep Neural Networks"
\newline \textit{British Computer Vision Conference (BMVC)}}

\vspace*{0.25em}

\cvitem{2015}{\textbf{Suraj Srinivas}, R. Venkatesh Babu. 
\newline ``Data-free Parameter Pruning for Deep Neural Networks"
\newline \textit{British Computer Vision Conference (BMVC)}}
%\clearpage

\cvsection{book chapters}

\cvitem{2017}{\textbf{Suraj Srinivas}, Ravi Kiran Sarvadevabhatla, Konda Reddy Mopuri, Nikita Prabhu, Srinivas SS Kruthiventi, R. Venkatesh Babu. 
\newline ``A taxonomy of deep convolutional neural nets for computer vision'', \newline Book chapter: \textit{Deep Learning for Medical Image Analysis, Elsevier}
\newline Journal version: \textit{Frontiers in Robotics and AI}}
\vspace*{0.25em}

\cvsection{talks} 

\cvitem{03/2023}{\textit{Pitfalls and Opportunities with Feature Importance Methods} \newline \href{https://www.merl.com/news/talk-20230314-1473}{MERL seminar series}, Boston}

\cvitem{07/2022}{\textit{Pitfalls and Opportunities with Feature Attribution Methods}
    \newline Simons Institute, UC Berkeley}

\cvitem{06/2022}{\textit{Pitfalls and Opportunities with Feature Attribution Methods}
    \newline Vanderbilt University, USA}

\cvitem{03/2022}{\textit{Cyclical Pruning for Neural Network Sparsity}
    \newline Google Sparsity Reading Group}

\cvitem{08/2021}{\textit{Pitfalls of Saliency Map Interpretation in Deep Neural Networks} 
    \newline HES-SO, Sierre, Switzerland}

\cvitem{05/2021}{\textit{Pitfalls of Saliency Map Interpretation in Deep Neural Networks} 
    \newline Harvard University, USA}

\cvitem{04/2021}{\textit{Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability} \newline ICLR (virtual)}

\cvitem{01/2020}{\textit{Neural Network Interpretability using
Full-Gradient Representation} \newline  Indian Institute of Science, Bangalore}

\cvitem{01/2020}{\textit{Full-Gradient Representation for Neural Network Visualization} \newline \href{http://mlclub.net}{ML for Astrophysicists Club} }

\cvitem{11/2019}{\textit{Full-Gradient Representation for Neural Network
Visualization} \newline Swiss Machine Learning Day, Lausanne} 

\cvitem{05/2019}{\textit{Complete Saliency Maps using Full-Jacobians} \newline Valais / Wallis AI
workshop, Martigny} 

\cvitem{07/2018}{\textit{Knowledge Transfer with Jacobian
Matching} \newline ICML, Stockholm} 

\cvitem{07/2016}{\textit{Making Deep Neural
Networks Smaller and Faster} \newline Deep Learning Conf, Bangalore}

\cvsection{reviewing}
\cvitem{Conferences}{AAAI, CVPR, ECCV, NeurIPS (2020) ; WACV, ICML, ICCV, NeurIPS (2021); 
 \newline ICLR, ICML, NeurIPS (2022); ICLR, AISTATS (2023)}
\cvitem{Journals}{IEEE SP-Letters, Elsevier Neural Networks, IEEE T-PAMI, Nature Communications}
%\vspace*{0.15cm}

%\clearpage
\cvsection{teaching}
\cvitem{2023}{Co-instructor for \textit{Interpretability and Explainability in ML} (CS-282BR) \newline Harvard University, USA}
\cvitem{2018, '19, '21}{Teaching Assistant for \textit{Deep Learning}  (EE-559) ($\times 3$) \newline EPFL, Switzerland}
\cvitem{2021}{Guest Lecturer on Interpretability for \textit{Deep Learning for Computer Vision} (DS-265) \newline Indian Institute of Science, Bangalore}
\clearpage 

\cvsection{awards and honors}
\cvitem{2022}{Best paper award at ICML \textit{Interpretable ML for Healthcare} Workshop}
\cvitem{2022}{Highlighted Reviewer at \textit{International Conference on Learning Representations (ICLR)}}
\cvitem{2021}{EPFL PhD Thesis Distinction Award for top 8\% thesis in the dept. of EE}
\cvitem{2019}{ICML travel grant for ICML 2019}
\cvitem{2017}{Best paper award at NeurIPS \textit{Learning with Limited Data} Workshop} 
\cvitem{2015}{Xerox Research India travel grant for BMVC 2015}
\cvitem{2014}{Ranked 399 (out of $\sim$ 200k candidates) in the nation-wide Graduate Aptitude Test in Engineering for entrance to graduate school in electronics and communications engineering}
\cvitem{2012}{First place at the E-Yantra nation-wide robotics contest held at IIT-Bombay, and featured in The Times of India, New Indian Express and DH Education}
\cvitem{2010}{Ranked 191 (out of $\sim$ 100k candidates) in the state-wide Common Entrance Test for entrance to undergraduate engineering programmes.} 

\clearpage

\end{document}
