---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: profile
title: About
---

## About me

I am a postdoctoral research fellow at Harvard University where I work with [Prof. Hima Lakkaraju](https://himalakkaraju.github.io/) on the interpretability and robustness of deep learning models. 

I completed my PhD at [Idiap Research Institute](http://www.idiap.ch/en) & [EPFL](http://epfl.ch/) in Switzerland, where I was advised by [Prof. Fran√ßois Fleuret](https://www.idiap.ch/~fleuret/). Before this, I completed my Masters (by Research) at the [Indian Institute of Science, Bangalore](http://www.iisc.ac.in/) advised by [Prof. R. Venkatesh Babu](http://cds.iisc.ac.in/faculty/venky/).

During my PhD, I interned at Qualcomm AI Research in Amsterdam, where I worked with [Tijmen Blankevoort](https://www.linkedin.com/in/tijmen-blankevoort-a5633a24/).

<p style="border-width:2px; border-style:none; background-color:seashell; padding: 1em;">
<b>I'm on the job market</b>. Do not hesitate to contact me regarding any interesting opportunities!
</p>

## Research

Deep learning is the dark matter of machine learning: ubiquitous yet profoundly mysterious. I believe that understanding deep learning is one of the most important fundamental open problems in science today.

To this end, I'm broadly interested in mathematically understanding deep learning models, and using this understanding to improve them and better apply them to real world applications. My research so far has focussed on the **robustness**, **interpretability** and **efficiency** of models at test time, but I am also interested in topics such as generative modelling, deep learning theory, and continual and lifelong learning. I am particularly interested in applications of machine learning in high-impact domains such as healthcare and robotics. Some questions I have worked on in the past:
- Why are gradients of deep classifiers perceptually aligned with human perception when this alignment is unnecessary for good performance? ([1](https://openreview.net/forum?id=dYeAHXnpWJ4), [2](https://arxiv.org/abs/2305.19101))  
- What are feature attribution methods in literature formally trying to achieve? ([3](https://arxiv.org/abs/2206.01254))
- Are neural networks more non-linear than they need to be? ([4](https://arxiv.org/abs/2206.07144)) 

My <a href="/publications.html">publications</a> page contains more information.

[//]: # (**Research interests**: interpretability, robustness, model efficiency, generative modelling, theory of deep learning, continual and lifelong learning)


