
\documentclass[12pt,a4paper,sans,english]{moderncv}        % possible options include font size ('10pt', '11pt' and '12pt'), paper size ('a4paper', 'letterpaper', 'a5paper', 'legalpaper', 'executivepaper' and 'landscape') and font family ('sans' and 'roman')
\moderncvstyle{classic}                             % style options are 'casual' (default), 'classic', 'oldstyle' and 'banking'
\moderncvcolor{red}                               % color options 'blue' (default), 'orange', 'green', 'red', 'purple', 'grey' and 'black'
\nopagenumbers{}                                  % uncomment to suppress automatic page numbering for CVs longer than one page
%\usepackage[utf8]{inputenc}                       % if you are not using xelatex ou lualatex, replace by the encoding you are using
\usepackage[a4paper, margin=2cm, left=1.5cm]{geometry}
\usepackage{setspace}
\usepackage{amssymb}
\usepackage{fontawesome}
\RequirePackage[unicode]{hyperref}
\hypersetup{colorlinks = true,
            linkcolor = blue,
            urlcolor  = teal,
            citecolor = blue,
            anchorcolor = blue}
%\usepackage{babel}
%\usepackage{hyperref}
\setstretch{1.05}
\newcommand{\cvsection}[1]{\vspace{0.3cm}\subsection{\large{#1}}}
%\newcommand{\cvitem}[2]{def}
%----------------------------------------------------------------------------------
%            personal data
%----------------------------------------------------------------------------------
\firstname{\hspace{1em}\textcolor{darkgray}{\Huge{Suraj Srinivas}}}
\familyname{}
% \\ \vspace*{0.1cm} \normalsize{\faGlobe ~\href{https://suraj-srinivas.github.io}{suraj-srinivas.github.io}  $\cdot$  \faEnvelope~ ssrinivas@seas.harvard.edu $\cdot$  suuraj.srinivas@gmail.com} }
                                 
                                  
\begin{document}
%-----       resume       ---------------------------------------------------------
%\vspace*{-1cm}

\makecvtitle

\vspace{-1.5cm}
\textcolor{gray}{\hrule}

\cvsection{Contact Information}
\cvitem{}{6.220, 150 Western Ave \newline Harvard University, Boston, MA \vspace{1ex}\newline suuraj.srinivas@gmail.com \newline ssrinivas@seas.harvard.edu \newline \href{https://suraj-srinivas.github.io}{suraj-srinivas.github.io}}

\cvsection{Research Interests}
\cvitem{}{Robustness, Interpretability \& Computational Efficiency of Deep models;  \newline Generative modelling; Representation learning}

%\vspace{0.5cm}

\cvsection{Work Experience}
\cventry{01/2022 \newline - Present}{Postdoctoral Research Fellow}{}{\newline Harvard University, USA}
{\newline \textbf{Advisor}: Prof. Hima Lakkaraju
\newline \textbf{Duties}: 
Academic research $\cdot$ Technical guidance \& mentoring $\cdot$ Teaching}{}

\cvsection{Education}
\cventry{2017 \newline - 2021}{Doctor of Philosophy}{}
{ \newline \'{E}cole Polytechnique F\'{e}d\'{e}rale de Lausanne \& \newline Idiap Research Institute, Switzerland}
{ \newline \textbf{Advisor}: Prof. Fran\c{c}ois Fleuret}
{}
\vspace*{0.5em}

\cventry{2014\newline - 2017}{Master of Science (Engineering)}{}{\newline Indian Institute of Science, Bangalore, India}{ \newline \textbf{Advisor}: Prof. R. Venkatesh Babu}{} 
\vspace*{0.5em}

\cventry{2010 - 2014}{Bachelor of Engineering}{}{\newline Electronics and Communication Engineering, \newline PES Institute of Technology~(Now PES University), Bangalore, India}{}{} 

\cvsection{Internships}

\cventry{08/2020 \newline - 01/2021}{Research Intern}{Qualcomm AI Research, Netherlands}{\newline Research on algorithms
to sparsify neural networks}{}{}

\cventry{06/2016 \newline - 08/2016}{Research Intern}{DataGrokr, India / Verisk
Analytics, USA}{\newline Speeding up inference on deep neural networks using tensor factorization}{}{}

\cventry{01/2014 \newline - 06/2014}{Engineering Intern}{Tonbo Imaging, Bangalore}{}{\newline Implemented image
processing algorithms on FPGA for a thermal imaging camera}{}

\cventry{06/2013 \newline - 08/2013}{Research Intern}{Indian Institute of Science, Bangalore}{}{\newline
Research on computational photography to perform camera jitter compensation}{}
\clearpage
\cvsection{Publications}
\vspace*{-0.3cm}
\subsection{\small{\href{https://bit.ly/2keccl6}{Google Scholar Profile}}}

\vspace{0.25cm}
\cvitem{2023} {Anna Meyer*, Dan Ley*, \textbf{Suraj Srinivas$^\dagger$}, Hima Lakkaraju. ($^\dagger$advising role) \newline ``On Minimizing the Impact of Dataset Shifts on Actionable Explanations'' \newline{\textit{Uncertainty in Artificial Intelligence (UAI)}} - \textbf{Oral}
}
\vspace*{0.25em}


\cvitem{2022} {\textbf{Suraj Srinivas}*, Kyle Matoba*, Hima Lakkaraju, Fran\c{c}ois Fleuret. (*co-first-author) \newline ``Efficient Training of Low-Curvature Neural Networks'' \newline{\textit{Neural Information Processing Systems (NeurIPS)}}
}
\vspace*{0.25em}

\cvitem{2022} {Tessa Han, \textbf{Suraj Srinivas$^\dagger$}, Hima Lakkaraju. ($^\dagger$advising role)
\newline ``Which Explanation Should I Choose? A Function Approximation Perspective to Characterizing Post hoc Explanations''
\newline \textit{Neural Information Processing Systems (NeurIPS)} \newline \textit{ICML Interpretable ML for Healthcare Workshop} - \textbf{Best Paper Award}}
\vspace*{0.25em}

\cvitem{2022} {Marwa El Halabi, \textbf{Suraj Srinivas}, Simon Lacoste-Julien.
\newline ``Data-Efficient Structured Pruning via Submodular Optimization" \newline \textit{Neural Information Processing Systems (NeurIPS)}}

\vspace*{0.25em}
\cvitem{2022} {\textbf{Suraj Srinivas}, Andrey Kuzmin, Markus Nagel, Mart van Baalen, \newline Andrii Skliar, Tijmen Blankevoort. \newline ``Cyclical Pruning for Sparse Neural Networks" 
\newline \textit{Computer Vision and Pattern Recognition Workshops (CVPRW)} - \textbf{Oral}}

\vspace*{0.25em}
\cvitem{2021}{\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret. \newline ``Rethinking the Role of Gradient-based Attribution Methods in Model Interpretability" 
\newline \textit{International Conference on Learning Represetations (ICLR)} - \textbf{Oral}
}
\vspace*{0.25em}

\cvitem{2019} {\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret. \newline ``Full-Gradient Representation
for Neural Network Visualization" \newline \textit{Neural Information Processing Systems (NeurIPS)}
}
\vspace*{0.25em}

\cvitem{2018} {\textbf{Suraj Srinivas}, Fran\c{c}ois Fleuret.
\newline ``Knowledge Transfer with Jacobian Matching" 
\newline \textit{International Conference on Machine Learning (ICML)}
\newline \textit{NeurIPS Learning with Limited Data (LLD) Workshop} - \textbf{Best Paper Award}
}
\vspace*{0.25em}

\cvitem{2017}{\textbf{Suraj Srinivas}, Akshayvarun Subramanya, R. Venkatesh Babu. 
\newline ``Training
Sparse Neural Networks"
\newline \textit{Computer Vision and Pattern Recognition Workshops (CVPRW)} - \textbf{Oral} }

\vspace*{0.25em}

\cvitem{2016}{\textbf{Suraj Srinivas}, R. Venkatesh Babu. 
\newline ``Learning the Architecture of Deep Neural Networks"
\newline \textit{British Computer Vision Conference (BMVC)}}

\vspace*{0.25em}

\cvitem{2015}{\textbf{Suraj Srinivas}, R. Venkatesh Babu. 
\newline ``Data-free Parameter Pruning for Deep Neural Networks"
\newline \textit{British Computer Vision Conference (BMVC)}}

\clearpage
\cvsection{Book Chapters}

\cvitem{2017}{\textbf{Suraj Srinivas}, Ravi Kiran Sarvadevabhatla, Konda Reddy Mopuri, Nikita Prabhu, Srinivas SS Kruthiventi, R. Venkatesh Babu. 
\newline ``A taxonomy of deep convolutional neural nets for computer vision'', \newline Book chapter: \textit{Deep Learning for Medical Image Analysis, Elsevier}
\newline Journal version: \textit{Frontiers in Robotics and AI}}
\vspace*{0.25em}

\cvsection{Talks} 

\cvitem{03/2023}{\textit{Pitfalls and Opportunities with Feature Importance Methods} \newline \href{https://www.merl.com/news/talk-20230314-1473}{MERL seminar series}, Boston}

\cvitem{07/2022}{\textit{Pitfalls and Opportunities with Feature Attribution Methods}
    \newline Simons Institute, UC Berkeley}

\cvitem{06/2022}{\textit{Pitfalls and Opportunities with Feature Attribution Methods}
    \newline Vanderbilt University, USA}

\cvitem{03/2022}{\textit{Cyclical Pruning for Neural Network Sparsity}
    \newline Google Sparsity Reading Group}

\cvitem{08/2021}{\textit{Pitfalls of Saliency Map Interpretation in Deep Neural Networks} 
    \newline HES-SO, Sierre, Switzerland}

\cvitem{05/2021}{\textit{Pitfalls of Saliency Map Interpretation in Deep Neural Networks} 
    \newline Harvard University, USA}

\cvitem{04/2021}{\textit{Rethinking the Role of Gradient-based Attribution Methods for Model Interpretability} \newline ICLR (virtual)}

\cvitem{01/2020}{\textit{Neural Network Interpretability using
Full-Gradient Representation} \newline  Indian Institute of Science, Bangalore}

\cvitem{01/2020}{\textit{Full-Gradient Representation for Neural Network Visualization} \newline \href{http://mlclub.net}{ML for Astrophysicists Club} }

\cvitem{11/2019}{\textit{Full-Gradient Representation for Neural Network
Visualization} \newline Swiss Machine Learning Day, Lausanne} 

\cvitem{05/2019}{\textit{Complete Saliency Maps using Full-Jacobians} \newline Valais / Wallis AI
workshop, Martigny} 

\cvitem{07/2018}{\textit{Knowledge Transfer with Jacobian
Matching} \newline ICML, Stockholm} 

\cvitem{07/2016}{\textit{Making Deep Neural
Networks Smaller and Faster} \newline Deep Learning Conf, Bangalore}

\cvsection{Reviewing}
\cvitem{Conferences}{AAAI, CVPR, ECCV, NeurIPS (2020) ; WACV, ICML, ICCV, NeurIPS (2021); 
 \newline ICLR, ICML, NeurIPS (2022); ICLR, AISTATS (2023)}
\cvitem{Journals}{IEEE SP-Letters, Elsevier Neural Networks, IEEE T-PAMI, Nature Communications}
%\vspace*{0.15cm}
\clearpage
\cvsection{Teaching}
\cvitem{2023}{Co-instructor for \textit{Interpretability and Explainability in ML} (CS-282BR) \newline Harvard University, USA}
\cvitem{2018, '19, '21}{Teaching Assistant for \textit{Deep Learning}  (EE-559) \newline EPFL, Switzerland}
\cvitem{2021}{Guest Lecturer on Interpretability for \textit{Deep Learning for Computer Vision} (DS-265) \newline Indian Institute of Science, Bangalore}

\cvsection{Research Mentoring}
\cvitem{2022-23}{Tessa Han (PhD candidate, Harvard) \newline \textit{Local Function Approximation to Characterize Explanations, NeurIPS 2022} \newline \textit{Uncertainty Quantification via Local Linear Approximations} }
\cvitem{2023}{Usha Bhalla (PhD student, Harvard) \newline \textit{Dataset Distillation for Interpretability}}
\cvitem{2023}{Daniel Ley (PhD student, Harvard) \newline \textit{On Minimizing the Impact of Dataset Shifts on Actionable Explanations, UAI 2023}}
\cvitem{2022}{Vincent Micheli \& Karthigan Sinnathamby (M.Sc. students, EPFL) \newline \textit{Multi-task Reinforcement Learning with a Planning Quasi-Metric}}
\cvitem{2017}{Akshayvarun Subramanya (Research Assistant, IISc) \newline \textit{Estimating Confidence for Deep Neural Networks via Density Modeling, SPCOM 2017} }
\cvitem{2016}{Lokesh Boominathan (Research Assistant, IISc) \newline \textit{Compensating for Large In-plane Rotations in Natural Images, ICVGIP 2016}}
%\newline \textit{Indian Conference on Vision, Graphics and Image Processing (ICVGIP), 2016}}

\cvsection{Outreach}
\cvitem{2023}{Co-organizing ``XAI in Action: Past, Present, and Future Applications'' \newline \textit{NeurIPS 2023 workshop} (upcoming)}

\cvsection{Awards and Honors}
\cvitem{2022}{Best paper award at ICML \textit{Interpretable ML for Healthcare} Workshop}
\cvitem{2022}{Highlighted Reviewer at \textit{International Conference on Learning Representations (ICLR)}}
\cvitem{2021}{EPFL PhD Thesis Distinction Award for top 8\% thesis in the dept. of   EE}
\cvitem{2017}{Best paper award at NeurIPS \textit{Learning with Limited Data} Workshop} 
%\cvitem{2015}{Received Xerox Research India travel grant to travel to BMVC 2015}
\cvitem{2014}{Ranked \textbf{399} (out of $\sim$ 200k candidates) nation-wide in the Graduate Aptitude Test in Engineering for entrance to graduate school in electronics and communications engineering}
\cvitem{2012}{Won first place at the E-Yantra nation-wide robotics contest held at IIT-Bombay, and featured in The Times of India, New Indian Express and DH Education}
%\cvitem{2011-2013}{Served as writer and later technology editor of the college magazine}
%\cvitem{2011-2013}{Founded Robotics club at college, organized and conducted workshops on "Introduction to Arduino" and "Introduction to Robotics", participated in and organized robotics competitions}
%\cvitem{2011}{Served as a volunteer English \& computer science teacher for local underprivileged schools}
\cvitem{2010}{Ranked \textbf{191} (out of $\sim$ 100k candidates) state-wide in the Karnataka Common Entrance Test for entrance to undergraduate engineering programmes.} 

\clearpage

\cvsection{References}
\cvitem{}{Prof. Himabindu Lakkaraju \newline Harvard University, USA \newline \texttt{hlakkaraju@hbs.edu}}
\vspace{2ex}

\cvitem{}{Prof. Francois Fleuret \newline University of Geneva, Switzerland \newline \texttt{francois.fleuret@unige.ch}}
\vspace{2ex}

\cvitem{}{Prof. R. Venkatesh Babu \newline Indian Institute of Science, Bangalore \newline \texttt{venky@iisc.ac.in}}
\vspace{2ex}


\end{document}
