---
# Feel free to add content and custom Front Matter to this file.
# To modify the layout, see https://jekyllrb.com/docs/themes/#overriding-theme-defaults

layout: profile
title: About
---

## About me

I am a postdoctoral research fellow at Harvard University where I work with [Prof. Hima Lakkaraju](https://himalakkaraju.github.io/) on the intersection of interpretability and robustness in deep learning.

I completed my PhD at [Idiap Research Institute](http://www.idiap.ch/en) & [EPFL](http://epfl.ch/) in Switzerland, where I was advised by [Prof. Fran√ßois Fleuret](https://www.idiap.ch/~fleuret/). Before this, I completed my Masters (by Research) at the [Indian Institute of Science, Bangalore](http://www.iisc.ac.in/) advised by [Prof. R. Venkatesh Babu](http://cds.iisc.ac.in/faculty/venky/).

During my PhD, I interned at Qualcomm AI Research in Amsterdam, where I worked with [Tijmen Blankevoort](https://www.linkedin.com/in/tijmen-blankevoort-a5633a24/).

<p style="border-width:2px; border-style:none; background-color:seashell; padding: 1em;">
<b>I'm on the job market</b>. If you think I'd be a good fit to your organization, do not hesitate to contact me!
</p>

## Research

Deep learning is like the dark matter problem in physics: both are ubiquitous yet profoundly mysterious. I believe that understanding deep learning is one of the most important fundamental open problems in science today.

To this end, I'm broadly interested in mathematically understanding deep learning models, and using this understanding to improve them. My research so far has focussed on the **robustness**, **interpretability** and **efficiency** of models at test time, but I am also interested in topics such as generative modelling, deep learning theory, and continual and lifelong learning. Some questions I have worked on in the past:
- Why are gradients of deep classifiers perceptually aligned with human perception when this alignment is unnecessary for good performance? ([1](https://openreview.net/forum?id=dYeAHXnpWJ4), [2](https://arxiv.org/abs/2305.19101))  
- What are feature attribution methods in literature formally trying to achieve? ([3](https://arxiv.org/abs/2206.01254))
- Are neural networks more non-linear than they need to be? ([4](https://arxiv.org/abs/2206.07144)) 

[//]: # (**Research interests**: interpretability, robustness, model efficiency, generative modelling, theory of deep learning, continual and lifelong learning)


